# -*- coding: utf-8 -*-
"""ImageClassification (1).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1H7xNs66rQt4CUUtu3UY1SXfkgmdObBNW
"""

from google.colab import drive
drive.mount('/content/drive')

!wget 'https://storage.googleapis.com/kaggle-data-sets/1330220/2215025/bundle/archive.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20230321%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20230321T090534Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=7d2b6933d23345bf3aac26708aa4c2c7ea8691ff76cc64d574f4d054a312af672d2f211f3f628dbe3802825a2678b0139c4ae517ef5fe79c552860de419ee6f4af688d485404dd777134358f5d4488d9bde66eb19093ade2f4ed19f977e878f12a8b7c07cc035b5f1a63fd21b7efe3b67d4709c807a3b1fa366fae625992a7525325a394ccf918baf9ff29822503d50fb13889d117706a7309390c07e2a27e09861ff4e9726340a350b9e6564bc202dc243b05f01afebc06a97011ad92602751caae8035485bd8e2bccec8124d5f6c9eb8676d40481be725cafe9ae952d770744ba80b3fad9bc0a9b01ce6ffdddafab8c25fe0be57c699b0aa8705767307446f' -O archive.zip

!unzip archive.zip -d"./drive/MyDrive/Colab Notebooks/"

!ls "./drive/MyDrive/Colab Notebooks/IOT_Malware_dataset/"

!mkdir dataset
!mkdir dataset/test dataset/test/malware dataset/test/benign
!mkdir dataset/train dataset/train/malware dataset/train/benign
!mkdir dataset/validation dataset/validation/malware dataset/validation/benign

!apt install tree

!tree -d "dataset"

import os
import shutil

def split_func(source_dir, name):

  test = "./dataset/test/"+name
  train = "./dataset/train/"+name
  valid = "./dataset/validation/"+name

  # Create a list of files in the source directory
  file_list = os.listdir(source_dir)

  # Calculate the number of files in each partition
  total_size = len(file_list)

  # Copy files to the first destination directory
  for i in range(int(total_size*0.8)):
      shutil.copy(os.path.join(source_dir, file_list[i]), test)
  print("test")
  # Copy files to the second destination directory
  for i in range(int(total_size*0.8), int(total_size*0.9)):
      shutil.copy(os.path.join(source_dir, file_list[i]), train)
  print("train")
  # Copy files to the third destination directory
  for i in range(int(total_size*0.9), int(total_size)):
      shutil.copy(os.path.join(source_dir, file_list[i]), valid)
  print("validation")

malware_path = "./drive/MyDrive/Colab Notebooks/IOT_Malware_dataset/Malware/"
benign_path = "./drive/MyDrive/Colab Notebooks/IOT_Malware_dataset/Benign/"
split_func(benign_path, "benign")
split_func(malware_path, "malware")

# !ls "./drive/MyDrive/Colab Notebooks/IOT_Malware_dataset/test/benign" | wc

from keras.preprocessing.image import ImageDataGenerator

# Set up image data generators for train and test sets
train_dir = './dataset/train/'
test_dir = './dataset/test/'
validation_dir = './dataset/validation/'
batch_size = 32
#images loaded

train_datagen = ImageDataGenerator(rescale=1./255)
test_datagen = ImageDataGenerator(rescale=1./255)
validation_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(224, 224),
    batch_size=batch_size,
    class_mode='binary')

test_generator = test_datagen.flow_from_directory(
    test_dir,
    target_size=(224, 224),
    batch_size=batch_size,
    class_mode='binary')

validation_generator = validation_datagen.flow_from_directory(
    validation_dir,
    target_size=(224, 224),
    batch_size=batch_size,
    class_mode='binary')

"""**Vgg16**"""

import os
import numpy as np
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D, MaxPooling2D
from keras.applications.vgg16 import VGG16

# Load the VGG16 model and remove the final layer
base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
x = base_model.output
x = Flatten()(x)
x = Dense(256, activation='relu')(x)
x = Dropout(0.5)(x)
predictions = Dense(1, activation='sigmoid')(x)

# Create a new model by combining the VGG16 base model and the new layers
model = Sequential()
model.add(base_model)
model.add(Flatten())
model.add(Dense(256, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(1, activation='sigmoid'))

model.summary()

print(model.input_shape)
print(model.output_shape)

# Freeze the VGG16 base layers and train the new layers
for layer in base_model.layers:
    layer.trainable = False

model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])
model.fit_generator(
    train_generator,
    steps_per_epoch=train_generator.samples // batch_size,
    epochs=20,
    validation_data=validation_generator,
    validation_steps=validation_generator.samples // batch_size)

# Save the model
model.save('./drive/MyDrive/Colab Notebooks/malware_detector_vgg16.h5')

from keras.models import load_model

# Load the saved model
model = load_model('./drive/MyDrive/Colab Notebooks/malware_detector_vgg16.h5')

# Evaluate the model on the "test" set
test_loss, test_acc = model.evaluate_generator(test_generator, steps=test_generator.samples // batch_size)

print('Test accuracy:', test_acc)
print('Test loss:', test_loss)

"""**ResNet**"""

from tensorflow.keras.applications.resnet50 import ResNet50
from keras.layers import Dense, Flatten, Dropout
from keras.models import Sequential

# Create the base model with pre-trained weights
base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Build the new layers on top of the base model
model = Sequential()
model.add(base_model)
model.add(Flatten())
model.add(Dense(256, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(1, activation='sigmoid'))

# Compile the model with optimizer, loss and metrics
model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])

# Train the model using generator
model.fit_generator(
    train_generator,
    steps_per_epoch=train_generator.samples // batch_size,
    epochs=20,
    validation_data=validation_generator,
    validation_steps=validation_generator.samples // batch_size)

# Save the model
model.save('./drive/MyDrive/Colab Notebooks/malware_detector_resnet.h5')

from keras.models import load_model

# Load the saved model
model = load_model('./drive/MyDrive/Colab Notebooks/malware_detector_resnet.h5')

# Evaluate the model on the "test" set
test_loss, test_acc = model.evaluate_generator(test_generator, steps=test_generator.samples // batch_size)

print('Test accuracy:', test_acc)
print('Test loss:', test_loss)

import os
import numpy as np
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D, MaxPooling2D
from keras.applications.vgg19 import VGG19

# Load the VGG19 model and remove the final layer
base_model = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
x = base_model.output
x = Flatten()(x)
x = Dense(256, activation='relu')(x)
x = Dropout(0.5)(x)
predictions = Dense(1, activation='sigmoid')(x)

# Create a new model by combining the VGG19 base model and the new layers
model = Sequential()
model.add(base_model)
model.add(Flatten())
model.add(Dense(256, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(1, activation='sigmoid'))

model.summary()

print(model.input_shape)
print(model.output_shape)

# Freeze the VGG19 base layers and train the new layers
for layer in base_model.layers:
    layer.trainable = False
model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])
model.fit_generator(
    train_generator,
    steps_per_epoch=train_generator.samples // batch_size,
    epochs=20,
    validation_data=validation_generator,
    validation_steps=validation_generator.samples // batch_size)

# Save the model
model.save('./drive/MyDrive/Colab Notebooks/malware_detector_vgg19.h5')

from keras.models import load_model

# Load the saved model
model = load_model('./drive/MyDrive/Colab Notebooks/malware_detector_vgg19.h5')

# Evaluate the model on the "test" set
test_loss, test_acc = model.evaluate_generator(test_generator, steps=test_generator.samples // batch_size)

print('Test accuracy:', test_acc)
print('Test loss:', test_loss)

"""**changing optimisers**"""

import os
import numpy as np
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D, MaxPooling2D
from keras.applications.vgg16 import VGG16

# Load the VGG16 model and remove the final layer
base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
x = base_model.output
x = Flatten()(x)
x = Dense(256, activation='relu')(x)
x = Dropout(0.5)(x)
predictions = Dense(1, activation='sigmoid')(x)

# Create a new model by combining the VGG16 base model and the new layers
model = Sequential()
model.add(base_model)
model.add(Flatten())
model.add(Dense(256, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(1, activation='sigmoid'))

model.summary()

print(model.input_shape)
print(model.output_shape)

# Freeze the VGG16 base layers and train the new layers
for layer in base_model.layers:
    layer.trainable = False

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
model.fit_generator(
    train_generator,
    steps_per_epoch=train_generator.samples // batch_size,
    epochs=20,
    validation_data=validation_generator,
    validation_steps=validation_generator.samples // batch_size)

# Save the model
model.save('./drive/MyDrive/Colab Notebooks/malware_detector_vgg16_adam.h5')

from keras.models import load_model

# Load the saved model
model = load_model('./drive/MyDrive/Colab Notebooks/malware_detector_vgg16_adam.h5')

# Evaluate the model on the "test" set
test_loss, test_acc = model.evaluate_generator(test_generator, steps=test_generator.samples // batch_size)

print('Test accuracy:', test_acc)
print('Test loss:', test_loss)

import os
import numpy as np
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D, MaxPooling2D
from keras.applications.vgg16 import VGG16

# Load the VGG16 model and remove the final layer
base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
x = base_model.output
x = Flatten()(x)
x = Dense(256, activation='relu')(x)
x = Dropout(0.5)(x)
predictions = Dense(1, activation='sigmoid')(x)

# Create a new model by combining the VGG16 base model and the new layers
model = Sequential()
model.add(base_model)
model.add(Flatten())
model.add(Dense(256, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(1, activation='sigmoid'))

model.summary()

print(model.input_shape)
print(model.output_shape)

# Freeze the VGG16 base layers and train the new layers
for layer in base_model.layers:
    layer.trainable = False

model.compile(optimizer='adamax', loss='binary_crossentropy', metrics=['accuracy'])
model.fit_generator(
    train_generator,
    steps_per_epoch=train_generator.samples // batch_size,
    epochs=20,
    validation_data=validation_generator,
    validation_steps=validation_generator.samples // batch_size)

# Save the model
model.save('./drive/MyDrive/Colab Notebooks/malware_detector_vgg16_adamax.h5')

from keras.models import load_model

# Load the saved model
model = load_model('./drive/MyDrive/Colab Notebooks/malware_detector_vgg16_adamax.h5')

# Evaluate the model on the "test" set
test_loss, test_acc = model.evaluate_generator(test_generator, steps=test_generator.samples // batch_size)

print('Test accuracy:', test_acc)
print('Test loss:', test_loss)

import os
import numpy as np
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D, MaxPooling2D
from keras.applications.vgg16 import VGG16

# Load the VGG16 model and remove the final layer
base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
x = base_model.output
x = Flatten()(x)
x = Dense(256, activation='relu')(x)
x = Dropout(0.5)(x)
predictions = Dense(1, activation='sigmoid')(x)

# Create a new model by combining the VGG16 base model and the new layers
model = Sequential()
model.add(base_model)
model.add(Flatten())
model.add(Dense(256, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(1, activation='sigmoid'))

model.summary()

print(model.input_shape)
print(model.output_shape)

# Freeze the VGG16 base layers and train the new layers
for layer in base_model.layers:
    layer.trainable = False

model.compile(optimizer='adadelta', loss='binary_crossentropy', metrics=['accuracy'])
model.fit_generator(
    train_generator,
    steps_per_epoch=train_generator.samples // batch_size,
    epochs=20,
    validation_data=validation_generator,
    validation_steps=validation_generator.samples // batch_size)

# Save the model
model.save('./drive/MyDrive/Colab Notebooks/malware_detector_vgg16_adadelta.h5')

from keras.models import load_model

# Load the saved model
model = load_model('./drive/MyDrive/Colab Notebooks/malware_detector_vgg16_adadelta.h5')

# Evaluate the model on the "test" set
test_loss, test_acc = model.evaluate_generator(test_generator, steps=test_generator.samples // batch_size)

print('Test accuracy:', test_acc)
print('Test loss:', test_loss)

from keras.models import load_model

# Load the saved model
model1 = load_model('./drive/MyDrive/Colab Notebooks/malware_detector_vgg16.h5')
model2 = load_model('./drive/MyDrive/Colab Notebooks/malware_detector_vgg16_adam.h5')
model3 = load_model('./drive/MyDrive/Colab Notebooks/malware_detector_vgg16_adamax.h5')
model4 = load_model('./drive/MyDrive/Colab Notebooks/malware_detector_vgg16_adadelta.h5')

import pickle

with open('./drive/MyDrive/Colab Notebooks/history_adadekta.pkl', 'rb') as f:
    history = pickle.load(f)

import matplotlib.pyplot as plt
import pickle

with open('./drive/MyDrive/Colab Notebooks/history_adam.pkl', 'rb') as f:
    history = pickle.load(f)

# Load the training history from a file
# history = load_training_history('vgg16_training_history.txt')

# Extract the training and validation loss from the history
train_loss = history['loss']
val_loss = history['val_loss']

# Extract the training and validation accuracy from the history
train_acc = history['accuracy']
val_acc = history['val_accuracy']

# Plot the training and validation loss
plt.plot(train_loss, label='Training Loss')
plt.plot(val_loss, label='Validation Loss')
plt.title('Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()

# Plot the training and validation accuracy
plt.plot(train_acc, label='Training Accuracy')
plt.plot(val_acc, label='Validation Accuracy')
plt.title('Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

!ls './drive/MyDrive/Colab Notebooks/'

import matplotlib.pyplot as plt
import pickle

with open('./drive/MyDrive/Colab Notebooks/history_adadekta.pkl', 'rb') as f:
    history = pickle.load(f)

# Extract the training and validation loss from the history
train_loss = history['loss']
val_loss = history['val_loss']

# Extract the training and validation accuracy from the history
train_acc = history['accuracy']
val_acc = history['val_accuracy']

# Create a figure with a single subplot
fig, ax = plt.subplots()

# Plot the training and validation loss
ax.plot(train_loss, label='Training Loss')
ax.plot(val_loss, label='Validation Loss')
ax.set_ylabel('Loss')
ax.set_xlabel('Epoch')
ax.set_title('Training and Validation Loss and Accuracy')

# Create a twin y-axis for accuracy
ax2 = ax.twinx()

# Plot the training and validation accuracy
ax2.plot(train_acc, label='Training Accuracy', color='tab:orange')
ax2.plot(val_acc, label='Validation Accuracy', color='tab:green')
ax2.set_ylabel('Accuracy')

# Add legend to the plot
lines1, labels1 = ax.get_legend_handles_labels()
lines2, labels2 = ax2.get_legend_handles_labels()
ax2.legend(lines1 + lines2, labels1 + labels2, loc='upper left')

# Display the plot
plt.show()

from keras.models import load_model
import time
import numpy as np
from sklearn.metrics import precision_score, recall_score, f1_score
# Load the saved model

for filename in os.listdir('./drive/MyDrive/Colab Notebooks/'):
  if(not filename.endswith('.h5')):
    continue
  print("\n\n")
  print(filename)
  model = load_model('./drive/MyDrive/Colab Notebooks/'+filename)

  # Get the predicted probabilities for the test set
  start_time = time.time()
  y_pred = model.predict(test_generator)
  end_time = time.time()
  time_delay = end_time - start_time
  y_pred_std = np.std(y_pred)

  # Convert the probabilities to binary predictions (0 or 1)
  y_pred_binary = np.round(y_pred)

  # Get the true labels for the test set
  y_true = test_generator.labels

  # Calculate the precision, recall, and F1 score
  precision = precision_score(y_true, y_pred_binary)
  recall = recall_score(y_true, y_pred_binary)
  f1 = f1_score(y_true, y_pred_binary)

  # Print the results
  print("Precision:", precision)
  print("Recall:", recall)
  print("F1 Score:", f1)
  print("Time Delay:", time_delay)
  print("Standard Deviation:", y_pred_std)

!ls './drive/MyDrive/Colab Notebooks/'

from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt

# Define the colors and labels for each model
colors = ['r', 'g', 'b']
labels = ['VGG16', 'VGG19', 'ResNet50']
line_styles = ['-', '--', ':']

model1 = load_model('./drive/MyDrive/Colab Notebooks/malware_detector_vgg16.h5')
model2 = load_model('./drive/MyDrive/Colab Notebooks/malware_detector_vgg19.h5')
model3 = load_model('./drive/MyDrive/Colab Notebooks/malware_detector_resnet.h5')

# Loop over each model
for i, model in enumerate([model1, model2, model3]):
    # Get the predicted probabilities for the test set
    y_pred = model.predict(test_generator)

    # Calculate the false positive rate, true positive rate, and threshold
    fpr, tpr, thresholds = roc_curve(test_generator.labels, y_pred)

    # Calculate the area under the curve (AUC)
    roc_auc = auc(fpr, tpr)

    # Plot the ROC curve for the current model
    if(i==0):
      plt.plot(fpr, tpr, color=colors[i], label='{} (AUC = {:.2f})'.format(labels[i], roc_auc))
    else:
      plt.plot(fpr, tpr, color=colors[i], linestyle=line_styles[i], label='{} (AUC = {:.2f})'.format(labels[i], roc_auc))

# Set the plot title and axis labels
plt.title('Receiver Operating Characteristic')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')

# Set the legend and show the plot
plt.legend()
plt.show()

import numpy as np
from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt
from keras.models import load_model

model1 = load_model('./drive/MyDrive/Colab Notebooks/malware_detector_vgg16.h5')
model2 = load_model('./drive/MyDrive/Colab Notebooks/malware_detector_vgg19.h5')
model3 = load_model('./drive/MyDrive/Colab Notebooks/malware_detector_resnet.h5')
# Get the true labels for the test data
y_test = test_generator.classes

# Use the predict() method of each model on the test generator to get the predicted probabilities
preds1 = model1.predict(test_generator)
preds2 = model2.predict(test_generator)
preds3 = model3.predict(test_generator)

# Convert the predicted probabilities to binary labels (0 or 1) by thresholding at 0.5
preds1_binary = np.round(preds1)
preds2_binary = np.round(preds2)
preds3_binary = np.round(preds3)

# y_pred = model.predict(test_generator)

fpr1, tpr1, threshold1 = roc_curve(y_test, preds1)
roc_auc1 = auc(fpr1, tpr1)

fpr2, tpr2, threshold2 = roc_curve(y_test, preds2)
roc_auc2 = auc(fpr2, tpr2)

fpr3, tpr3, threshold3 = roc_curve(y_test, preds3)
roc_auc3 = auc(fpr3, tpr3)

# Plot the ROC curves
plt.title('Receiver Operating Characteristic')
plt.plot(fpr1, tpr1, 'b', label = 'Model 1 AUC = %0.2f' % roc_auc1)
plt.plot(fpr2, tpr2, 'g', label = 'Model 2 AUC = %0.2f' % roc_auc2)
plt.plot(fpr3, tpr3, 'r', label = 'Model 3 AUC = %0.2f' % roc_auc3)
plt.legend(loc = 'lower right')
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0, 1])
plt.ylim([0, 1])
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.show()
